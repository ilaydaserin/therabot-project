{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPrX6gQgGwSUNW2NJVZ5a0g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"collapsed":true,"id":"MMM0ZmQSAKP4","executionInfo":{"status":"ok","timestamp":1734948843132,"user_tz":-180,"elapsed":9406,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"0e78b36c-7bd6-482c-bac6-fea68110d034"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n","Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["!pip install transformers datasets"]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"-TQi57GCAZ3L","executionInfo":{"status":"ok","timestamp":1734948874202,"user_tz":-180,"elapsed":21081,"user":{"displayName":"Artemis","userId":"15957525884195404406"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Veri setini yükle\n","dataset = load_dataset(\"nbertagnolli/counsel-chat\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"collapsed":true,"id":"Nd0MDwi-ApPb","executionInfo":{"status":"ok","timestamp":1734948931893,"user_tz":-180,"elapsed":946,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"e047f152-bb89-4576-9c52-630e4cc37875"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]}]},{"cell_type":"code","source":["dataset.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"R6xvbH6lBXbr","executionInfo":{"status":"ok","timestamp":1734949044325,"user_tz":-180,"elapsed":473,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"e11a05af-2e81-4bf1-8384-822180aeb247"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['train'])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Eksik verileri temizle\n","def clean_data(dataset):\n","    # Pandas DataFrame'e dönüştür\n","    df = pd.DataFrame(dataset)\n","\n","    # Eksik değerleri doldur\n","    df = df.dropna(subset=[\"questionText\", \"answerText\"])  # Boş sorular ve cevaplar çıkarılır\n","\n","    # Veriyi sadece gerekli kolonlarla sınırlı tut\n","    df = df[[\"questionText\", \"answerText\"]]\n","\n","    return df\n","\n","# Veri setini temizle\n","train_df = clean_data(dataset[\"train\"])\n","\n","# Eğitim ve doğrulama setine ayır\n","train_texts, val_texts = train_test_split(\n","    train_df, test_size=0.1, random_state=42  # %10 doğrulama seti\n",")\n","\n","# Eğitim ve doğrulama setlerini kontrol et\n","print(f\"Eğitim seti boyutu: {len(train_texts)}\")\n","print(f\"Doğrulama seti boyutu: {len(val_texts)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"SJe2rzBBAvCq","executionInfo":{"status":"ok","timestamp":1734949117916,"user_tz":-180,"elapsed":514,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"57de6cbb-87ab-4961-b41e-f81d68c1990b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Eğitim seti boyutu: 2350\n","Doğrulama seti boyutu: 262\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","import torch\n","\n","# DialoGPT model ve tokenizer'ı yükle\n","model_name = \"microsoft/DialoGPT-medium\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n","model = AutoModelForCausalLM.from_pretrained(model_name)"],"metadata":{"id":"CYkmu_4nAyCq","executionInfo":{"status":"ok","timestamp":1734949276411,"user_tz":-180,"elapsed":3138,"user":{"displayName":"Artemis","userId":"15957525884195404406"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Pad token'ı ayarla\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Veriyi token haline getirme\n","def tokenize_data(data):\n","    inputs = tokenizer(\n","        data[\"questionText\"].tolist(),\n","        max_length=128,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\",\n","    )\n","    targets = tokenizer(\n","        data[\"answerText\"].tolist(),\n","        max_length=128,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\",\n","    )\n","    inputs[\"labels\"] = targets[\"input_ids\"]\n","    return inputs\n","\n","# Eğitim ve doğrulama verilerini tokenleştir\n","train_encodings = tokenize_data(train_texts)\n","val_encodings = tokenize_data(val_texts)"],"metadata":{"id":"1AeHyEKFCHju","executionInfo":{"status":"ok","timestamp":1734949301579,"user_tz":-180,"elapsed":3662,"user":{"displayName":"Artemis","userId":"15957525884195404406"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# PyTorch Dataset sınıfı\n","class DialogueDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","    def __getitem__(self, idx):\n","        return {key: tensor[idx] for key, tensor in self.encodings.items()}\n","\n","# Dataset'leri oluştur\n","train_dataset = DialogueDataset(train_encodings)\n","val_dataset = DialogueDataset(val_encodings)"],"metadata":{"id":"KL1LMojiCV1R","executionInfo":{"status":"ok","timestamp":1734949314522,"user_tz":-180,"elapsed":272,"user":{"displayName":"Artemis","userId":"15957525884195404406"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Eğitim parametreleri\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    logging_dir=\"./logs\",\n","    logging_steps=500,\n","    save_steps=500,\n","    save_strategy=\"epoch\",\n","    report_to=\"none\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0ZZZYg3ACZ0_","executionInfo":{"status":"ok","timestamp":1734949343498,"user_tz":-180,"elapsed":263,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"77defa66-4d43-4bbd-baf2-d28542f4bca9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Trainer nesnesini oluştur\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n",")\n","\n","# Eğitimi başlat\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"60dS4vFGCg51","executionInfo":{"status":"ok","timestamp":1734950238250,"user_tz":-180,"elapsed":890225,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"8bdb0355-b5fd-4720-c45e-97e0f6de0faa"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-d84339e03ea3>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='882' max='882' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [882/882 14:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>5.883747</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>6.085400</td>\n","      <td>5.819700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>6.085400</td>\n","      <td>5.810968</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=882, training_loss=6.003578514739229, metrics={'train_runtime': 888.2407, 'train_samples_per_second': 7.937, 'train_steps_per_second': 0.993, 'total_flos': 1636834974105600.0, 'train_loss': 6.003578514739229, 'epoch': 3.0})"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Modeli kaydet\n","model.save_pretrained(\"./counsel_chat_dialoGPT\")\n","tokenizer.save_pretrained(\"./counsel_chat_dialoGPT\")\n","\n","print(\"Model eğitildi ve kaydedildi.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"NXB2CsgSCiEV","executionInfo":{"status":"ok","timestamp":1734950357864,"user_tz":-180,"elapsed":15297,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"a07570ce-7574-4a72-c9b1-39edf9a184fc"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model eğitildi ve kaydedildi.\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Eğitilen modeli ve tokenizer'ı yükle\n","model_path = \"./counsel_chat_dialoGPT\"  # Modelin kaydedildiği yol\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForCausalLM.from_pretrained(model_path)\n","\n","# Chatbot fonksiyonu\n","def chat_with_bot():\n","    print(\"Chatbot'a hoş geldiniz! Çıkmak için 'exit' yazabilirsiniz.\")\n","    chat_history = \"\"\n","\n","    max_history_length = 3  # Sohbet geçmişini sınırlamak için kullanılacak maksimum mesaj sayısı\n","\n","    while True:\n","        # Kullanıcıdan giriş al\n","        user_input = input(\"Siz: \")\n","\n","        # Çıkış komutunu kontrol et\n","        if user_input.lower() == \"exit\":\n","            print(\"Chatbot oturumu sonlandırıldı.\")\n","            break\n","\n","        # Sohbet geçmişini güncelle ve sınırla\n","        chat_history += f\"User: {user_input}\\nBot: \"\n","        chat_history_list = chat_history.split(tokenizer.eos_token)\n","        if len(chat_history_list) > max_history_length:\n","            chat_history_list = chat_history_list[-max_history_length:]\n","        chat_history = tokenizer.eos_token.join(chat_history_list)\n","\n","        # Girişi tokenleştir ve modelden yanıt al\n","        inputs = tokenizer.encode(chat_history + tokenizer.eos_token, return_tensors=\"pt\", truncation=True)\n","\n","        try:\n","            outputs = model.generate(\n","                inputs,\n","                max_length=150,\n","                temperature=1.2,  # Daha rastgele yanıtlar için sıcaklık artırıldı\n","                top_p=0.95,  # Top-p sampling\n","                top_k=50,    # Top-k sampling\n","                do_sample=True,  # Sampling etkinleştirildi\n","                repetition_penalty=1.2,  # Tekrarlı ifadeleri azaltır\n","                pad_token_id=tokenizer.eos_token_id,  # Padding token ayarlandı\n","            )\n","\n","            # Yanıtı çözümle\n","            response = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)\n","\n","            # Yanıt boşsa veya anlamlı değilse\n","            if not response.strip():\n","                response = \"Bunu anlamadım, tekrar dener misiniz?\"\n","\n","            print(f\"Chatbot: {response}\")\n","\n","            # Sohbet geçmişine bot yanıtını ekle\n","            chat_history += response + tokenizer.eos_token\n","\n","        except Exception as e:\n","            print(\"Bir hata oluştu:\", str(e))\n","            print(\"Lütfen girişinizi kontrol edin ve tekrar deneyin.\")\n","\n","# Chatbot'u başlat\n","chat_with_bot()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"KGN3o5nUGU3q","executionInfo":{"status":"error","timestamp":1734950865347,"user_tz":-180,"elapsed":36632,"user":{"displayName":"Artemis","userId":"15957525884195404406"}},"outputId":"01257126-2baf-42bd-b9d1-d85556ad5780"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Chatbot'a hoş geldiniz! Çıkmak için 'exit' yazabilirsiniz.\n","Siz: hello\n","Chatbot:  the\n","Siz: i feel bad\n","Chatbot: Bunu anlamadım, tekrar dener misiniz?\n","Siz: how are you\n","Chatbot: ! do your a\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-ab9bd6871ce0>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Chatbot'u başlat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mchat_with_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-ab9bd6871ce0>\u001b[0m in \u001b[0;36mchat_with_bot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Kullanıcıdan giriş al\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Siz: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Çıkış komutunu kontrol et\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":[],"metadata":{"id":"86Va4LlRLONs"},"execution_count":null,"outputs":[]}]}